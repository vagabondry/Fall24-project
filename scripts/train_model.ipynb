{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-10-26T11:01:31.457577Z","iopub.status.busy":"2024-10-26T11:01:31.456874Z","iopub.status.idle":"2024-10-26T11:01:44.267973Z","shell.execute_reply":"2024-10-26T11:01:44.266918Z","shell.execute_reply.started":"2024-10-26T11:01:31.457540Z"},"trusted":true},"outputs":[],"source":["#%pip install -q transformers"]},{"cell_type":"code","execution_count":2,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-10-26T11:01:49.015554Z","iopub.status.busy":"2024-10-26T11:01:49.015178Z","iopub.status.idle":"2024-10-26T11:02:01.486431Z","shell.execute_reply":"2024-10-26T11:02:01.485415Z","shell.execute_reply.started":"2024-10-26T11:01:49.015518Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting peft\n","  Downloading peft-0.13.2-py3-none-any.whl.metadata (13 kB)\n","Requirement already satisfied: numpy>=1.17 in c:\\users\\nika\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from peft) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in c:\\users\\nika\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from peft) (23.2)\n","Requirement already satisfied: psutil in c:\\users\\nika\\appdata\\roaming\\python\\python312\\site-packages (from peft) (5.9.8)\n","Requirement already satisfied: pyyaml in c:\\users\\nika\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from peft) (6.0.2)\n","Requirement already satisfied: torch>=1.13.0 in c:\\users\\nika\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from peft) (2.4.1)\n","Requirement already satisfied: transformers in c:\\users\\nika\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from peft) (4.45.1)\n","Requirement already satisfied: tqdm in c:\\users\\nika\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from peft) (4.66.5)\n","Requirement already satisfied: accelerate>=0.21.0 in c:\\users\\nika\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from peft) (0.34.2)\n","Requirement already satisfied: safetensors in c:\\users\\nika\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from peft) (0.4.5)\n","Requirement already satisfied: huggingface-hub>=0.17.0 in c:\\users\\nika\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from peft) (0.25.1)\n","Requirement already satisfied: filelock in c:\\users\\nika\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub>=0.17.0->peft) (3.13.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\nika\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub>=0.17.0->peft) (2024.2.0)\n","Requirement already satisfied: requests in c:\\users\\nika\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub>=0.17.0->peft) (2.32.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\nika\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub>=0.17.0->peft) (4.10.0)\n","Requirement already satisfied: sympy in c:\\users\\nika\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.13.0->peft) (1.12)\n","Requirement already satisfied: networkx in c:\\users\\nika\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.13.0->peft) (3.2.1)\n","Requirement already satisfied: jinja2 in c:\\users\\nika\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.13.0->peft) (3.1.3)\n","Requirement already satisfied: setuptools in c:\\users\\nika\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.13.0->peft) (69.2.0)\n","Requirement already satisfied: colorama in c:\\users\\nika\\appdata\\roaming\\python\\python312\\site-packages (from tqdm->peft) (0.4.6)\n","Requirement already satisfied: regex!=2019.12.17 in c:\\users\\nika\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers->peft) (2024.9.11)\n","Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\nika\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers->peft) (0.20.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\nika\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\nika\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nika\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\nika\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->huggingface-hub>=0.17.0->peft) (2.2.1)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nika\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.2.2)\n","Requirement already satisfied: mpmath>=0.19 in c:\\users\\nika\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n","Downloading peft-0.13.2-py3-none-any.whl (320 kB)\n","   ---------------------------------------- 0.0/320.7 kB ? eta -:--:--\n","   --- ------------------------------------ 30.7/320.7 kB 1.4 MB/s eta 0:00:01\n","   ---- ---------------------------------- 41.0/320.7 kB 495.5 kB/s eta 0:00:01\n","   ---- ---------------------------------- 41.0/320.7 kB 495.5 kB/s eta 0:00:01\n","   ---- ---------------------------------- 41.0/320.7 kB 495.5 kB/s eta 0:00:01\n","   ------ -------------------------------- 51.2/320.7 kB 175.0 kB/s eta 0:00:02\n","   -------- ------------------------------ 71.7/320.7 kB 231.8 kB/s eta 0:00:02\n","   -------- ------------------------------ 71.7/320.7 kB 231.8 kB/s eta 0:00:02\n","   ------------- ------------------------ 112.6/320.7 kB 285.2 kB/s eta 0:00:01\n","   ------------- ------------------------ 112.6/320.7 kB 285.2 kB/s eta 0:00:01\n","   ---------------- --------------------- 143.4/320.7 kB 304.6 kB/s eta 0:00:01\n","   -------------------------- ----------- 225.3/320.7 kB 444.3 kB/s eta 0:00:01\n","   --------------------------- ---------- 235.5/320.7 kB 424.3 kB/s eta 0:00:01\n","   -------------------------------- ----- 276.5/320.7 kB 473.7 kB/s eta 0:00:01\n","   -------------------------------------  317.4/320.7 kB 504.4 kB/s eta 0:00:01\n","   -------------------------------------- 320.7/320.7 kB 496.8 kB/s eta 0:00:00\n","Installing collected packages: peft\n","Successfully installed peft-0.13.2\n","Note: you may need to restart the kernel to use updated packages.\n"]},{"name":"stderr","output_type":"stream","text":["\n","[notice] A new release of pip is available: 24.0 -> 24.2\n","[notice] To update, run: python.exe -m pip install --upgrade pip\n"]}],"source":["#%pip install peft\n"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-10-26T11:02:10.059613Z","iopub.status.busy":"2024-10-26T11:02:10.059226Z","iopub.status.idle":"2024-10-26T11:02:15.306735Z","shell.execute_reply":"2024-10-26T11:02:15.305931Z","shell.execute_reply.started":"2024-10-26T11:02:10.059575Z"},"trusted":true},"outputs":[],"source":["from transformers import GPT2Tokenizer, GPT2LMHeadModel, AdamW, get_linear_schedule_with_warmup\n","from peft import LoraConfig, get_peft_model\n","import pandas as pd\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","from tqdm import tqdm\n"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-10-26T11:02:29.937063Z","iopub.status.busy":"2024-10-26T11:02:29.935850Z","iopub.status.idle":"2024-10-26T11:02:35.738340Z","shell.execute_reply":"2024-10-26T11:02:35.737230Z","shell.execute_reply.started":"2024-10-26T11:02:29.937018Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f3c933aacaf347b4afec574829fe7edd","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"44cc4c74a5f9431c826bc9c5c01bcc8b","version_major":2,"version_minor":0},"text/plain":["vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f8fec593b77b4bddac93a96025679a4c","version_major":2,"version_minor":0},"text/plain":["merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5215f3f514e74116808152403ca1eac9","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c489b2e08df9426093318b3092652930","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/762 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n"]}],"source":["tokenizer = GPT2Tokenizer.from_pretrained('distilgpt2')\n","tokenizer.add_special_tokens({'sep_token': '[SEP]'})\n","tokenizer.pad_token = tokenizer.eos_token"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-10-26T11:02:39.477463Z","iopub.status.busy":"2024-10-26T11:02:39.476624Z","iopub.status.idle":"2024-10-26T11:02:57.151353Z","shell.execute_reply":"2024-10-26T11:02:57.150337Z","shell.execute_reply.started":"2024-10-26T11:02:39.477421Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c27321b25b934cb39e3459a486bf4a2e","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/353M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5081f5d1fd2b4487816b91d24143f9ef","version_major":2,"version_minor":0},"text/plain":["generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/peft/tuners/lora/layer.py:1150: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n","  warnings.warn(\n"]}],"source":["model = GPT2LMHeadModel.from_pretrained('distilgpt2')\n","model.resize_token_embeddings(len(tokenizer))\n","\n","# Configure LoRA\n","lora_config = LoraConfig(\n","    r=4,                      \n","    lora_alpha=32,            \n","    lora_dropout=0.1,         \n","    target_modules=[\"c_attn\"] \n",")\n","\n","model = get_peft_model(model, lora_config)\n"]},{"cell_type":"markdown","metadata":{},"source":["# Dataset tokenization"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-10-26T11:03:02.569228Z","iopub.status.busy":"2024-10-26T11:03:02.568742Z","iopub.status.idle":"2024-10-26T11:03:02.878307Z","shell.execute_reply":"2024-10-26T11:03:02.876913Z","shell.execute_reply.started":"2024-10-26T11:03:02.569177Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["   Unnamed: 0                                                  0  \\\n","0           0            What kind of phone(s) do you guys have?   \n","1           1  I have a pixel. It's pretty great. Much better...   \n","2           2       Does it really charge all the way in 15 min?   \n","3           3            What kind of phone(s) do you guys have?   \n","4           4  Samsung Galaxy J1. It's my first cell phone an...   \n","\n","                                                   1  \\\n","0  I have a pixel. It's pretty great. Much better...   \n","1       Does it really charge all the way in 15 min?   \n","2  Pretty fast. I've never timed it, but it's und...   \n","3  Samsung Galaxy J1. It's my first cell phone an...   \n","4  What do you think of it? Anything you don't like?   \n","\n","                                                   2  \n","0       Does it really charge all the way in 15 min?  \n","1  Pretty fast. I've never timed it, but it's und...  \n","2  cool. I've been thinking of getting one, my ph...  \n","3  What do you think of it? Anything you don't like?  \n","4  I love it. I can't think of anything I don't l...  \n"]}],"source":["import pandas as pd\n","\n","df = pd.read_csv('/kaggle/input/reddit-conversations/casual_data_windows.csv')\n","\n","print(df.head())"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-10-26T11:04:21.565897Z","iopub.status.busy":"2024-10-26T11:04:21.564859Z","iopub.status.idle":"2024-10-26T11:04:22.997735Z","shell.execute_reply":"2024-10-26T11:04:22.996672Z","shell.execute_reply.started":"2024-10-26T11:04:21.565841Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["0    What kind of phone(s) do you guys have? [SEP] ...\n","1    I have a pixel. It's pretty great. Much better...\n","2    Does it really charge all the way in 15 min? [...\n","3    What kind of phone(s) do you guys have? [SEP] ...\n","4    Samsung Galaxy J1. It's my first cell phone an...\n","Name: formatted_text, dtype: object\n"]}],"source":["def format_conversation(row):\n","    if pd.notna(row['2']):\n","        return f\"{row['0']} [SEP] {row['1']} [SEP] {row['2']}\"\n","    else:\n","        return f\"{row['0']} [SEP] {row['1']}\"\n","\n","df['formatted_text'] = df.apply(format_conversation, axis=1)\n","\n","print(df['formatted_text'].head())\n"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-10-26T11:04:28.680461Z","iopub.status.busy":"2024-10-26T11:04:28.680076Z","iopub.status.idle":"2024-10-26T11:04:57.036640Z","shell.execute_reply":"2024-10-26T11:04:57.035734Z","shell.execute_reply.started":"2024-10-26T11:04:28.680423Z"},"trusted":true},"outputs":[],"source":["def tokenize_function(text):\n","    return tokenizer(text, return_special_tokens_mask=True, truncation=True, padding='max_length', max_length=512)\n","\n","# Tokenize the dataset\n","tokenized_datasets = df['formatted_text'].apply(tokenize_function)\n"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-10-26T11:05:00.663862Z","iopub.status.busy":"2024-10-26T11:05:00.663473Z","iopub.status.idle":"2024-10-26T11:05:00.671880Z","shell.execute_reply":"2024-10-26T11:05:00.670985Z","shell.execute_reply.started":"2024-10-26T11:05:00.663825Z"},"trusted":true},"outputs":[],"source":["class ConversationDataset(Dataset):\n","    def __init__(self, tokenized_texts):\n","        self.input_ids = [torch.tensor(t['input_ids']) for t in tokenized_texts]\n","        self.attention_masks = [torch.tensor(t['attention_mask']) for t in tokenized_texts]\n","\n","    def __len__(self):\n","        return len(self.input_ids)\n","\n","    def __getitem__(self, idx):\n","        return {\n","            'input_ids': self.input_ids[idx],\n","            'attention_mask': self.attention_masks[idx],\n","            'labels': self.input_ids[idx],  \n","        }"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-10-26T11:05:09.078838Z","iopub.status.busy":"2024-10-26T11:05:09.077908Z","iopub.status.idle":"2024-10-26T11:05:29.596265Z","shell.execute_reply":"2024-10-26T11:05:29.595310Z","shell.execute_reply.started":"2024-10-26T11:05:09.078795Z"},"trusted":true},"outputs":[{"data":{"text/plain":["PeftModel(\n","  (base_model): LoraModel(\n","    (model): GPT2LMHeadModel(\n","      (transformer): GPT2Model(\n","        (wte): Embedding(50258, 768)\n","        (wpe): Embedding(1024, 768)\n","        (drop): Dropout(p=0.1, inplace=False)\n","        (h): ModuleList(\n","          (0-5): 6 x GPT2Block(\n","            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (attn): GPT2SdpaAttention(\n","              (c_attn): lora.Linear(\n","                (base_layer): Conv1D(nf=2304, nx=768)\n","                (lora_dropout): ModuleDict(\n","                  (default): Dropout(p=0.1, inplace=False)\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=768, out_features=4, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=4, out_features=2304, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (c_proj): Conv1D(nf=768, nx=768)\n","              (attn_dropout): Dropout(p=0.1, inplace=False)\n","              (resid_dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (mlp): GPT2MLP(\n","              (c_fc): Conv1D(nf=3072, nx=768)\n","              (c_proj): Conv1D(nf=768, nx=3072)\n","              (act): NewGELUActivation()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","        (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (lm_head): Linear(in_features=768, out_features=50258, bias=False)\n","    )\n","  )\n",")"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["train_dataset = ConversationDataset(tokenized_datasets)\n","train_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-10-26T11:05:35.429233Z","iopub.status.busy":"2024-10-26T11:05:35.428791Z","iopub.status.idle":"2024-10-26T11:05:35.876664Z","shell.execute_reply":"2024-10-26T11:05:35.875905Z","shell.execute_reply.started":"2024-10-26T11:05:35.429187Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]}],"source":["optimizer = AdamW(model.parameters(), lr=2e-5)\n","num_epochs = 5\n","total_steps = len(train_dataloader) * num_epochs\n","scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)"]},{"cell_type":"markdown","metadata":{},"source":["# Training"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-10-26T11:05:44.960534Z","iopub.status.busy":"2024-10-26T11:05:44.959889Z","iopub.status.idle":"2024-10-26T16:38:28.472957Z","shell.execute_reply":"2024-10-26T16:38:28.471918Z","shell.execute_reply.started":"2024-10-26T11:05:44.960489Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 14075/14075 [1:06:27<00:00,  3.53it/s]\n","100%|██████████| 14075/14075 [1:06:34<00:00,  3.52it/s]\n","100%|██████████| 14075/14075 [1:06:33<00:00,  3.52it/s]\n","100%|██████████| 14075/14075 [1:06:33<00:00,  3.52it/s]\n","100%|██████████| 14075/14075 [1:06:34<00:00,  3.52it/s]\n"]}],"source":["model.train()\n","for epoch in range(num_epochs):\n","    for batch in tqdm(train_dataloader):\n","        optimizer.zero_grad()\n","        inputs = batch[\"input_ids\"].to(device)\n","        attention_mask = batch[\"attention_mask\"].to(device)\n","        labels = batch[\"labels\"].to(device)\n","\n","        outputs = model(input_ids=inputs, attention_mask=attention_mask, labels=labels)\n","        loss = outputs.loss\n","        loss.backward()\n","\n","        optimizer.step()\n","        scheduler.step()"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-10-26T16:44:57.752409Z","iopub.status.busy":"2024-10-26T16:44:57.751553Z","iopub.status.idle":"2024-10-26T16:45:00.103837Z","shell.execute_reply":"2024-10-26T16:45:00.103043Z","shell.execute_reply.started":"2024-10-26T16:44:57.752366Z"},"trusted":true},"outputs":[],"source":["model.save_pretrained(\"lora_fine_tuned_gpt2\")\n"]},{"cell_type":"markdown","metadata":{},"source":["# Evaluation"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: safetensors in c:\\users\\nika\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.4.5)Note: you may need to restart the kernel to use updated packages.\n","\n"]},{"name":"stderr","output_type":"stream","text":["\n","[notice] A new release of pip is available: 24.0 -> 24.2\n","[notice] To update, run: python.exe -m pip install --upgrade pip\n"]}],"source":["#%pip install safetensors\n"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-10-26T16:40:32.128334Z","iopub.status.busy":"2024-10-26T16:40:32.127946Z","iopub.status.idle":"2024-10-26T16:40:32.138213Z","shell.execute_reply":"2024-10-26T16:40:32.137043Z","shell.execute_reply.started":"2024-10-26T16:40:32.128299Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\Nika\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n"]},{"data":{"text/plain":["Embedding(50258, 768)"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["from transformers import GPT2Tokenizer, GPT2LMHeadModel\n","from peft import LoraConfig, get_peft_model, PeftModel, PeftConfig\n","\n","# Load the tokenizer\n","tokenizer = GPT2Tokenizer.from_pretrained('distilgpt2')\n","tokenizer.add_special_tokens({'sep_token': '[SEP]'})\n","tokenizer.pad_token = tokenizer.eos_token\n","model = GPT2LMHeadModel.from_pretrained(\"distilgpt2\")\n","model.resize_token_embeddings(len(tokenizer))\n","\n"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"data":{"text/plain":["PeftModel(\n","  (base_model): LoraModel(\n","    (model): GPT2LMHeadModel(\n","      (transformer): GPT2Model(\n","        (wte): Embedding(50258, 768)\n","        (wpe): Embedding(1024, 768)\n","        (drop): Dropout(p=0.1, inplace=False)\n","        (h): ModuleList(\n","          (0-5): 6 x GPT2Block(\n","            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (attn): GPT2SdpaAttention(\n","              (c_attn): lora.Linear(\n","                (base_layer): Conv1D(nf=2304, nx=768)\n","                (lora_dropout): ModuleDict(\n","                  (default): Dropout(p=0.1, inplace=False)\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=768, out_features=4, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=4, out_features=2304, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (c_proj): Conv1D(nf=768, nx=768)\n","              (attn_dropout): Dropout(p=0.1, inplace=False)\n","              (resid_dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (mlp): GPT2MLP(\n","              (c_fc): Conv1D(nf=3072, nx=768)\n","              (c_proj): Conv1D(nf=768, nx=3072)\n","              (act): NewGELUActivation()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","        (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (lm_head): Linear(in_features=768, out_features=50258, bias=False)\n","    )\n","  )\n",")"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["# Load the fine-tuned model\n","peft_config = PeftConfig.from_pretrained(\"lora_fine_tuned_gpt2\") \n","model = PeftModel.from_pretrained(model, \"lora_fine_tuned_gpt2\") \n","model.eval() \n"]},{"cell_type":"markdown","metadata":{},"source":["# Generation"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["\n","User: what do you do on a weekend?\n","Bot: I'm going to go out and eat dinner with my friends.\n","I'll be in the kitchen for lunch tomorrow morning, but it's not too late!\n"]}],"source":["input_text = \"what do you do on a weekend?\"\n","inputs = tokenizer(input_text, return_tensors=\"pt\")\n","outputs = model.generate(\n","    **inputs,\n","    max_length=50,\n","    min_length=10,\n","    temperature=1.0,\n","    top_k=500,\n","    top_p=0.7,\n","    no_repeat_ngram_size=2,\n","    repetition_penalty=4.0\n",")\n","generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n","response = generated_text[len(input_text):].strip()  \n","print(\"\\n\" + \"User: \" + input_text + \"\\n\" + \"Bot: \" + response)\n"]},{"cell_type":"markdown","metadata":{},"source":["# Sentiment analysis"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["\n","[notice] A new release of pip is available: 24.0 -> 24.2\n","[notice] To update, run: python.exe -m pip install --upgrade pip\n"]},{"name":"stdout","output_type":"stream","text":["Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["%pip install -q transformers\n","from transformers import pipeline\n","specific_model = pipeline(model=\"cardiffnlp/twitter-roberta-base-sentiment\")\n","\n"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"data":{"text/plain":["[{'label': 'LABEL_0', 'score': 0.9022073149681091},\n"," {'label': 'LABEL_0', 'score': 0.764986515045166}]"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["data = [\"you're insane\", \"how could you say that omg\"]\n","specific_model(data)"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":540134,"sourceId":986563,"sourceType":"datasetVersion"}],"dockerImageVersionId":30787,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.0"}},"nbformat":4,"nbformat_minor":4}
